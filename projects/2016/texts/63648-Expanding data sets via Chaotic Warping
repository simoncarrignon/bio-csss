Keywords
deep learning, time series classification, discretization

Summary
1.0. The goal.
Inspired by recent successes of deep learning in classification, we attempt to address a fundamental to the field problem of insufficient training data instances by developing a Chaos-based technique for data warping. 
Specifically, our goal is the development of a novel, deep learning-based solution for time series classification (TSC) problem based on Chaotic Warping. As the standard benchmark dataset (i.e [| the UCR dataset]) typically has very few instances in training data, which significantly affects training and cross-validation processes performance, we believe that our technique shall contribute to the whole community.

2.0. The approach taken.
Probably the best explanation of the problem and the approach, a different technique though, is given by Patrice Y. Simard, Dave Stdeinkraus, and John C. Platt in their work titled "Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis" [1] ...
"...Synthesizing plausible transformations of data is simple, but the “inverse” problem – transformation invariance – can be arbitrarily complicated. Fortunately, learning algorithms are very good at learning inverse problems. Given a classification task, one may apply transformations to generate additional data and let the learning algorithm infer the transformation invariance. This invariance is embedded in the parameters, so it is in some sense free, since the computation at recognition time is unchanged. If the data is scarce and if the distribution to be learned has transformation-invariance properties, generating additional data using transformations may even improve performance. In the case of handwriting recognition, we postulate that the distribution has some invariance with respect to not only affine transformations, but also elastic deformations corresponding to uncontrolled oscillations of the hand muscles, dampened by inertia..."

At the first prototyping iteration, for simplicity of the feasibility evaluation, we plan to re-use Diana Dabby's approach for variation (warping) of musical pitch sequences: "..The sensitive dependence property of chaotic trajectories offers a natural mechanism for variability. By affixing the pitch sequence of a musical work to a reference chaotic trajectory, it is possible to generate meaningful variations via a mapping between neighboring chaotic trajectories and the reference. The variations result from changes in the ordering of the pitch sequence. But two chaotic orbits started at nearly the same initial point in state space soon become uncorrelated. To counter this, the mapping was designed so that a nearby trajectory could often track the reference, thus tempering the extent of the separation. Tracking means that pitches in the variation appear exactly where they did in the source. However, regardless of whether the two trajectories track, the mapping links the variation with the original by ensuring only those pitch events found in the source piece comprise the variation..." For the next iteration we plan to re-use the Liz Bradley's technique or some other approach (if found)... 

Essentially, we would expect the Complexity warping to work somewhat similar to the displacement field transform which is illustrated on the figures below:



However, our approach will differ as we are going to build it upon the symbolic discretization and time series bitmaps illustrated on the figures below:

2.1. Symbolic Aggregate approXimation.
SAX transform the input time series into a string:



As shown, the input time series processed with three steps: (i) it is normalized to the mean of zero and a unit of standard deviation (z-normalization), (ii) Piecewise Aggregate Approximation (PAA) applied to the normalized time series, (iii) PAA coefficients are mapped to a Symbolic Aggregate approXimation (SAX) alphabet of size 3.

This SAX process is applied to the input time series via sliding window to transform it into a set of representative strings -- i.e. a window of size W slid across the time series and the subsequences extracted via the window are SAX-transformed with the PPA size P and the Alphabet size A.

2.2. Time series bitmap.




2.3. Neural net-based TSC.



Some References
Group Contact
Pavel Senin (seninp@gmail.com) 
Nicole M Beckage 
Pinar Ozisik

Interested Participants
